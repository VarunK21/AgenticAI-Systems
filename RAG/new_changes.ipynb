{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change the code of mistral ocr with that given by Manish\n",
    "- Store all the docs available in the Chroma DB already\n",
    "- Add document_name,page_num and chunk_num in the metadata of the chunks for the chroma DB (with unique id = doc_name+page_num+chunk_num) - upsert to tackle duplicate creation\n",
    "- Add chunk/document_name to context of each chunk so that it knows which document it is referring to while answerig the query\n",
    "- Test everything\n",
    "- Setup environment on local\n",
    "- Add case in metadata depending on which folder the file is read from\n",
    "- Also create a function to return df of pre onboarded files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import chromadb\n",
    "import os\n",
    "#from pdf2image import convert_from_path\n",
    "#import pytesseract\n",
    "from pathlib import Path\n",
    "from mistralai import Mistral\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wJyytaUHReShCZnFU3QMJdTVbPzOxhZh\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai_key=os.getenv(\"api_key_latest\")\n",
    "mistral_key=os.getenv(\"api_key_mistral\")\n",
    "print(mistral_key)\n",
    "print(openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mistral_ocr(pdf_path):\n",
    "\n",
    "    client = Mistral(api_key=mistral_key)\n",
    "    uploaded_pdf = client.files.upload(file={\"file_name\": pdf_path,\"content\": open(pdf_path, \"rb\")},purpose=\"ocr\")\n",
    "    client.files.retrieve(file_id=uploaded_pdf.id)\n",
    "\n",
    "    signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)\n",
    "\n",
    "    ocr_response = client.ocr.process(\n",
    "        model=\"mistral-ocr-latest\",\n",
    "        document={\n",
    "            \"type\": \"document_url\",\n",
    "            \"document_url\": signed_url.url,\n",
    "        },\n",
    "        include_image_base64=True\n",
    "    )\n",
    "\n",
    "    return ocr_response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ocr_response is the API response\n",
    "def replace_images_in_markdown_for_all_pages(ocr_response):\n",
    "    for i in range(len(ocr_response.pages)):\n",
    "        markdown = ocr_response.pages[i].markdown\n",
    "        images = ocr_response.pages[i].images\n",
    "\n",
    "        # Create a dictionary mapping image ids to base64 data for the current page\n",
    "        image_base64_dict = {image.id: image.image_base64 for image in images}\n",
    "\n",
    "        # Function to replace image references with base64 data in Markdown\n",
    "        def replace(match):\n",
    "            img_id = match.group(1)\n",
    "            base64_data = image_base64_dict.get(img_id)\n",
    "            if base64_data:\n",
    "                return f'![{img_id}]({base64_data})'\n",
    "            return match.group(0)\n",
    "\n",
    "        # Replace all image references in the current page's markdown\n",
    "        updated_markdown = re.sub(r'!(.*?)(.*?)', replace, markdown)\n",
    "\n",
    "        return updated_markdown\n",
    "        # Display the updated Markdown for the current page\n",
    "        #display(Markdown(updated_markdown))\n",
    "\n",
    "# Example usage:\n",
    "#a=replace_images_in_markdown_for_all_pages(ocr_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_summarization(base64_image):\n",
    "  \n",
    "  # Specify model\n",
    "  model = \"pixtral-12b-2409\"\n",
    "\n",
    "  # Initialize the Mistral client\n",
    "  client = Mistral(api_key=mistral_key)\n",
    "  prompt = \"\"\"Analyze the content of the image and extract the text present in it. Include descriptions of any visible text, objects, diagrams, graphs, or charts.\n",
    "              It should be in the same langage as the original image.\n",
    "              It should be a text.\n",
    "  \"\"\"\n",
    "  # Define the messages for the chat\n",
    "  messages = [\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\n",
    "                  \"type\": \"text\",\n",
    "                  \"text\": prompt\n",
    "              },\n",
    "              {\n",
    "                  \"type\": \"image_url\",\n",
    "                  \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "              }\n",
    "          ]\n",
    "      }\n",
    "  ]\n",
    "\n",
    "  # Get the chat response\n",
    "  chat_response = client.chat.complete(\n",
    "      model=model,\n",
    "      messages=messages,\n",
    "      max_tokens=2000,\n",
    "      temperature=0.001\n",
    "  )\n",
    "\n",
    "  return(\"image summary: \", chat_response.choices[0].message.content)\n",
    "\n",
    "def clean_base64(base64_str):\n",
    "    # Check if the base64 string contains the prefix and remove it if it does\n",
    "    if base64_str.startswith('data:image/jpeg;base64,'):\n",
    "        return base64_str.replace('data:image/jpeg;base64,', '')\n",
    "    return base64_str\n",
    "\n",
    "# Function to replace image references with the summary of the image in Markdown\n",
    "def replace_images_with_summary_in_markdown(ocr_response):\n",
    "    client=Mistral(mistral_key)\n",
    "    updated_markdown_list = []\n",
    "\n",
    "    for i in range(len(ocr_response.pages)):\n",
    "        markdown = ocr_response.pages[i].markdown\n",
    "        images = ocr_response.pages[i].images\n",
    "\n",
    "        # Create a dictionary mapping image ids to base64 data for the current page\n",
    "        image_base64_dict = {image.id: image.image_base64 for image in images}\n",
    "\n",
    "        # Function to replace image references with the summary of the image in Markdown\n",
    "        def replace(match):\n",
    "            img_id = match.group(1)\n",
    "            base64_data = image_base64_dict.get(img_id)\n",
    "\n",
    "            if base64_data:\n",
    "                # Clean the base64 string by removing the repeated prefix\n",
    "                cleaned_base64 = clean_base64(base64_data)\n",
    "                image_summary = image_summarization(client, cleaned_base64)\n",
    "                return f'[Image Summary: {img_id}] - {image_summary}'\n",
    "\n",
    "            return match.group(0)\n",
    "\n",
    "        #print(\"REPLACING STARTING\")\n",
    "        # Replace all image references in the current page's markdown with summaries\n",
    "        updated_markdown = re.sub(r'!(.*?)(.*?)', replace, markdown)\n",
    "        #print(\"REPLACING ENDING\")\n",
    "\n",
    "        # Store the updated Markdown\n",
    "        updated_markdown_list.append(updated_markdown)\n",
    "\n",
    "        # Display the updated Markdown for the current page\n",
    "        #display(Markdown(updated_markdown))\n",
    "\n",
    "    # Combine all pages into a single Markdown string\n",
    "    final_markdown = []\n",
    "    for i in range(len(updated_markdown_list)):\n",
    "        final_markdown.append((i+1,updated_markdown_list[i]))\n",
    "        \n",
    "    return final_markdown\n",
    "\n",
    "#final_markdown = replace_images_with_summary_in_markdown(ocr_response)\n",
    "\n",
    "#len(final_markdown)\n",
    "#final_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest documents\n",
    "def fetch_source_pagenum(directory_path):\n",
    "    #ocr = MistralOCR()\n",
    "    all_docs = []\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "      for file in files:\n",
    "          if file.lower().endswith(\".pdf\"):\n",
    "              # Get the immediate parent folder name\n",
    "              parent_folder = os.path.basename(root)\n",
    "              doc_path=os.path.join(directory_path,parent_folder,file)\n",
    "              print(doc_path)\n",
    "              \n",
    "              ocr_response=mistral_ocr(doc_path)\n",
    "              page_resp=\"\"\n",
    "              for page in ocr_response.pages:\n",
    "                page_resp+=page.markdown\n",
    "              \n",
    "              #final_markdown=replace_images_in_markdown_for_all_pages(page_resp)\n",
    "              #replace_images_in_markdown_for_all_pages(ocr_response)\n",
    "              #final_markdown = replace_images_with_summary_in_markdown(ocr_response)\n",
    "\n",
    "              \n",
    "              #ocr_results=read_pdf(doc_path)\n",
    "              #print(final_markdown[0])\n",
    "              for (i,page_content) in enumerate(page_resp):\n",
    "                  print(\"here - \",i)\n",
    "                  chunks = text_splitter.split_text(page_content)\n",
    "\n",
    "                  print(len(chunks))\n",
    "                  for chunk_num,chunk in enumerate(chunks):\n",
    "                      print(chunk_num,len(chunk))\n",
    "                      all_docs.append({\n",
    "                          \"page_content\": chunk,\n",
    "                          \"metadata\": {\"folder_name\":parent_folder,\"file_name\": file,\"page_number\": i,\"chunk_number\":chunk_num}\n",
    "                      })\n",
    "\n",
    "    return all_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chroma persistent client\n",
    "def create_chroma_client(emb_fn,persist_directory=\"chroma_db\"):\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "    collection = client.get_or_create_collection(name=\"rag\",embedding_function=emb_fn)\n",
    "    print(f\"Chroma client initialized with persistent path: {persist_directory}\")\n",
    "    return collection\n",
    "\n",
    "# Upsert chunks in batches\n",
    "def upsert_chunks_in_batches(collection, chunks, batch_size=100):\n",
    "    \"\"\"Upserts chunks into Chroma DB in batches.\"\"\"\n",
    "    for i in tqdm(range(0, len(chunks), batch_size), desc=\"Upserting Chunks\"):\n",
    "        batch = chunks[i : i + batch_size]\n",
    "\n",
    "        # Prepare documents and IDs\n",
    "        ids = [\n",
    "            f\"{chunk['metadata']['folder_name']}_{chunk['metadata']['file_name']}_\"\n",
    "            f\"page{chunk['metadata']['page_number']}_chunk{chunk['metadata']['chunk_number']}\"\n",
    "            for chunk in batch\n",
    "        ]\n",
    "        documents = [chunk[\"page_content\"] for chunk in batch]\n",
    "        metadatas = [chunk[\"metadata\"] for chunk in batch]\n",
    "\n",
    "        # Upsert in batch\n",
    "        collection.upsert(ids=ids, documents=documents, metadatas=metadatas)\n",
    "\n",
    "    print(f\"Upserted {len(chunks)} chunks in batches of {batch_size}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_onboarded_docs():  \n",
    "  client = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "  collection = client.get_or_create_collection(name=\"rag\",embedding_function=openai_ef)\n",
    "  doc_df=pd.DataFrame.from_dict(collection.get())\n",
    "  return doc_df[[\"folder_name\",\"file_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_query,openai_ef, llm,k=5):\n",
    "    # Get the collection from Chroma client\n",
    "    persist_path = \"chroma_db\"  # Replace with your actual path\n",
    "    client = chromadb.PersistentClient(path=persist_path)\n",
    "\n",
    "    collection = client.get_or_create_collection(name=\"rag\",embedding_function=openai_ef)\n",
    "\n",
    "    # Fetch relevant chunks using similarity search\n",
    "    relevant_chunks = collection.query(\n",
    "        query_texts=[user_query],\n",
    "        n_results=k\n",
    "    )\n",
    "\n",
    "    print(relevant_chunks)\n",
    "    # Extract page content and metadata from the relevant chunks\n",
    "    context = \"\"\n",
    "    for i in range(len(relevant_chunks[\"documents\"][0])):\n",
    "        page_content = relevant_chunks[\"documents\"][0][i]\n",
    "        metadata = relevant_chunks[\"metadatas\"][0][i]\n",
    "\n",
    "        context += f\"Metadata: {metadata}\\n\\n\"\n",
    "        context += f\"Page Content: {page_content}\\n\"\n",
    "\n",
    "    # Construct enhanced query for LLM\n",
    "    enhanced_query = (\n",
    "        \"You are a helpful assistant that answers questions by reasoning through provided content.\\n\"\n",
    "        \"Analyze the relevant information from the documents below and provide a detailed reasoning before giving the final answer.\\n\"\n",
    "        \"Cite the page numbers and sources in your reasoning.\\n\\n\"\n",
    "        f\"{context}\"\n",
    "        f\"User Query: {user_query}\\n\\n\"\n",
    "        \"Provide a detailed response that includes:\\n\"\n",
    "        \"A brief final answer for the user query followed by a detailed explanation stating which supporting documents were found based on which you gave the answer and on which pages they were found.\\n\"\n",
    "    )\n",
    "\n",
    "    # Prompt the LLM with the enhanced query\n",
    "    response = llm.invoke(enhanced_query)\n",
    "\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_key=os.getenv(\"api_key_latest\")\n",
    "mistral_key=os.getenv(\"api_key_mistral\")\n",
    "print(mistral_key)\n",
    "print(openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_to_store=fetch_source_pagenum(\"/content/Documents/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=openai_key,\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )\n",
    "\n",
    "llm=ChatOpenAI(api_key=openai_key, model=\"gpt-4o-2024-11-20\", temperature=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_response(\"What was the main argument our office raised in its first defense brief?\",openai_ef,llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
